---
title: "PSD coefficients for modelling" # title of the notebook
author: "Virginie Sonnet" 
date: 2025-09-10
description: 
    Process the particle size distribution from the UVP to QC, extract the coefficients of the polynomial curve and prepare for Cephalopod input. 
html: 
theme: sandstone
#mainfont: "LM Roman"
fontsize: 0.99em
toc: true # table of contents
toc-depth: 5 
toc-location: left # table of contents on the left 
lightbox: TRUE # allows to click on an image to zoom in the HTML document
embed-resources: true # avoid having dependencies in an extra folder
smooth-scroll: true
editor: visual
code-overflow: wrap
code-fold: false
execute:
    eval: true # run the code chunks FALSE/TRUE
    echo: true # print the source code FALSE/TRUE
    error: true # print error messages FALSE/TRUE
    message: false # print any message FALSE/TRUE
    warning: false # print warning message FALSE/TRUE
    cache: false 
---

```{r}
#| eval: false
#| echo: false

Other outputs: pdf_document, html_notebook, word_document 
The HTML below just says to use the "LM Roman" family as font (kind of Arial?) and if you want the Latex font, you just need "Latin Modern Roman". The line below indicates that the text has to be justified. 
```

```{r}
#| include: false

# make sure that no object is in the environment and collect the garbage 
rm(list=ls())
gc()
```

```{r}
#| results: hide

library(tidyverse)
source(here::here("config.R"))
```

# Data

------------------------------------------------------------------------

```{r}
sp <- read_csv(file.path(cfg$project$data,"UVP_particles/particles_uvp_kiko2021_samples.csv"))
uvppart <- read_csv(file.path(cfg$project$data,"UVP_particles/particles_uvp_kiko2021_particles.csv"))
```

Let's add the real names and geometric size associated with the classes:

```{r}
# class names
names <- tibble(classname=colnames(uvppart)) %>% 
  mutate(lower=as.numeric(str_extract(classname,"(?<=ESD:\\s?)\\d+\\.?\\d+")), # find decimal after ESD: with or without spaces
         upper=as.numeric(str_extract(classname,"(?<=-)\\d+\\.?\\d+"))) %>% 
  # geometric mean 
  mutate(geometric_mean=sqrt(lower * upper))
```

# QC

------------------------------------------------------------------------

## Size range

Only keep classes 23 (mean \> 0.2mm) to 37 (mean \< 5mm). Below 23 are inconsistent classes across instruments, above 37 are too rare classes.

```{r}
uvppart <- uvppart %>% 
  pivot_longer(`Part conc frac [#/l] (ESD: 0.0403-0.0508 mm)`:`Part conc frac [#/l] (ESD: >26 mm)`,
               names_to="classname",
               values_to="conc") %>% 
  left_join(names) %>% 
  filter(geometric_mean > 0.2 & geometric_mean < 5)
```

## Abundance threshold

Consider that if there are 4 or less ROI (particles) in a size bin, then all upper size bins should be removed. There wasn't enough volume and particle sampled to have a statistical distribution and consider this is representative of the water column rather than driven by chance encounters.

TODO: need to add a check so that you don't remove 0 abundances that are between two correct values (or look at it - but seems to be a small number of data)

```{r}
uvppart <- uvppart %>% 
  # convert to abundance 
  mutate(abundance=watervolume*conc) %>% 
  # make sure the data is ordered by sample, depth and size class
  arrange(psampleid, depth, geometric_mean) %>%
  # for each sample depth, set size classes to 0 when you hit 4 or less ROI
  group_by(psampleid, depth,geometric_mean) %>%
  mutate(abundance = ifelse(cumany(abundance <= 4), 0, abundance)) %>%
  ungroup() %>% 
  # remove the size classes set to 0 
  filter(abundance != 0)
gc()
```

## Number of classes threshold

This QC needs to take into account the number of classes left (i.e. 3 classes, especially the first ones will focus on the small bell shape at the beginning rather than the whole spectra shape). If you have less than 4 classes, the samples are removed.

```{r}
uvppart %>% 
  count(psampleid,depth) %>% 
  ggplot(aes(x=n)) +
  geom_histogram(color="white",fill="black")

uvppart <- uvppart %>% 
  group_by(psampleid,depth) %>% 
  filter(n() >= 4)
gc()
```

## Depth

We focus on the surface (15-225m - chosen to have a minimum of matchups) and the open ocean (bottom depth \> 200m). However, for these samples, we do not always have a bottom depth so we can approximate it by considering that the UVP generally is lowered throughout the water column, and as such that if the maximum UVP depth is higher than 200m we consider the sample as open ocean.

Note that this criteria will need to be adjusted for gliders in the extensive version.

```{r}
uvppart <- uvppart %>%
  # onlly keep samples with max depth > 200 (approximation, no depth bottom here - remove 2000)
  group_by(psampleid) %>% 
  mutate(depth_bottom=max(depth)) %>%
  filter(depth_bottom >= 200) %>% 
  # focus on the depths between 15 and 150m
  filter(depth > 15 & depth < 225)
gc()
```

# Processing

------------------------------------------------------------------------

## Concentration

Not needed in the version using Kiko et al 2021, probably needed for the EcoPart export.

```{r}
#uvppart <- uvppart %>% 
#  # correct the abundance by the water volume sampled
#  mutate(conc=abundance/watervolume)
```

## Surface concentration: median over 225m and log10 transformation

```{r}
uvppart <- uvppart %>%
  # log-transformed median concentration over depth 
  group_by(psampleid,geometric_mean) %>% 
  summarize(logconc=log10(median(conc))) %>% 
  # log-transformed size 
  mutate(logsize=log10(geometric_mean))
```

## Coefficients

We do a polynomial fit of degree 2, following the suggestion from Ranini et al. that this follows the curve better than a linear fit.

```{r}
# group the data by sampleid
fitted_models <- uvppart %>%
  arrange(psampleid,geometric_mean) %>%
  group_by(psampleid) %>%
  do({
    # fit a polynomial model of degree 2
    model <- lm(logconc ~ logsize + I(logsize^2), data = .)
    
    # rmse
    rmse_val <- sqrt(mean(residuals(model)^2))
    
    # extract coefficients
    coefs <- broom::tidy(model)
    coefs %>% 
      bind_rows(tibble(
        term = "RMSE",
        estimate = rmse_val,
      ))
  }) %>%
  ungroup()

# pivot the coefficients to wide format for easier access
coefficients <- fitted_models %>%
  select(psampleid,term,estimate) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>%
  rename(Intercept = `(Intercept)`, Linear = `logsize`, Quadratic = `I(logsize^2)`) %>% 
  # remove samples with NA (92)
  filter(!is.na(Quadratic)) %>% 
  pivot_longer(Intercept:RMSE,names_to = "term", values_to = "estimate") 
```

# Cephalopod

------------------------------------------------------------------------

## Formatting

Note that Cephalopod will need to be updated for negative values, and that Cephalopod-factor (Sonnet et al.) will be used for depth-resolved bins and QC in the extensive version.

```{r}
cephalopod <- coefficients %>% 
  filter(term != "RMSE") %>% 
  group_by(term) %>% 
  mutate(worms_id=term,
         # correct the negative values of the coefficients for Cephalopod
         estimate=estimate+abs(min(estimate))) %>% 
  ungroup() %>% 
  rename(measurementvalue=estimate) %>% 
  left_join(distinct(sp,psampleid,
                   decimallatitude=latitude,
                   decimallongitude=longitude,
                   sampledate)) %>% 
  # set arbitrary depth, it will only be used in filtering 
  mutate(depth=150,
         measurementunit="no unit",
         scientificname=worms_id,
         taxonrank="Genus",
         month=month(sampledate),
         year=year(sampledate)) %>% 
  select(psampleid,measurementvalue,measurementunit,worms_id,scientificname,taxonrank,month,year,depth,decimallatitude,decimallongitude)
```

## Export

We can export it to our running session.

```{r}
write_csv(cephalopod,file.path(cfg$project$data,"cephalopod_power_law_coefficients.csv"))
```

And copy it to our internal storage.

```{bash}
mc cp ~/work/PSDtoCarbonExport-short/data/cephalopod_power_law_coefficients.csv s3/oidc-vsonnet
```

```{r}
rm(list=ls())
gc()
```
